diff --git hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/AbstractDNSToSwitchMapping.java hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/AbstractDNSToSwitchMapping.java
index b1f0fb2..bfd84f7 100644
--- hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/AbstractDNSToSwitchMapping.java
+++ hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/AbstractDNSToSwitchMapping.java
@@ -23,6 +23,7 @@ import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.conf.Configurable;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.CommonConfigurationKeys;
+import org.apache.hadoop.util.ReflectionUtils;
 
 import java.util.HashMap;
 import java.util.HashSet;
@@ -115,7 +116,7 @@ public abstract class AbstractDNSToSwitchMapping
     StringBuilder builder = new StringBuilder();
     builder.append("Mapping: ").append(toString()).append("\n");
     if (rack != null) {
-      builder.append("Map:\n");
+      builder.append("Known mappings:\n");
       Set<String> switches = new HashSet<String>();
       for (Map.Entry<String, String> entry : rack.entrySet()) {
         builder.append("  ")
@@ -153,4 +154,24 @@ public abstract class AbstractDNSToSwitchMapping
         && ((AbstractDNSToSwitchMapping) mapping).isSingleSwitch();
   }
 
+  /**
+   * Create a mapping from the configuration that is guaranteed to be caching.
+   * That means either it is wrapped in a caching mapper, or that it it
+   * does not need to be.
+   * @param conf configuration
+   * @return an AbstractDNSToSwitchMapping which caches hostname to rack mappings
+   * @throws RuntimeException on any problems loading the class.
+   */
+  public static AbstractDNSToSwitchMapping createCachingDNSToSwitchMapping(Configuration conf) {
+    DNSToSwitchMapping rawMapping = ReflectionUtils.newInstance(
+        conf.getClass(
+            CommonConfigurationKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,
+            ScriptBasedMapping.class,
+            DNSToSwitchMapping.class), conf);
+    AbstractDNSToSwitchMapping mapping;
+    mapping = (rawMapping instanceof CachedDNSToSwitchMapping) ?
+         (CachedDNSToSwitchMapping)rawMapping
+        : new CachedDNSToSwitchMapping(rawMapping);
+    return mapping;
+  }
 }
diff --git hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/ScriptBasedMapping.java hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/ScriptBasedMapping.java
index a41a424..772b3e5 100644
--- hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/ScriptBasedMapping.java
+++ hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/ScriptBasedMapping.java
@@ -262,7 +262,7 @@ public final class ScriptBasedMapping extends CachedDNSToSwitchMapping {
 
     @Override
     public String toString() {
-      return scriptName != null ? ("script " + scriptName) : NO_SCRIPT;
+      return scriptName != null ? ("script \"" + scriptName + "\"") : NO_SCRIPT;
     }
   }
 }
diff --git hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TableMapping.java hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TableMapping.java
index 277432b..e8367d3 100644
--- hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TableMapping.java
+++ hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TableMapping.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.net;
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY;
 
 import java.io.BufferedReader;
+import java.io.File;
 import java.io.FileReader;
 import java.io.IOException;
 import java.util.ArrayList;
@@ -142,6 +143,25 @@ public class TableMapping extends CachedDNSToSwitchMapping {
       }
       return results;
     }
-    
+
+    /**
+     * String method provides information about the chosen table file
+     * and the current mapping
+     * @return some details about the mapping.
+     */
+    @Override
+    public String toString() {
+      String filename =
+          getConf().get(NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY, "");
+      StringBuilder builder = new StringBuilder();
+      builder.append("TableMapping with table \"").append(filename)
+          .append("\"\n");
+      if(!filename.isEmpty()) {
+        File file = new File(filename);
+        builder.append("Path: ").append(file.getAbsolutePath()).append("\n");
+      }
+      builder.append("Map size: ").append(map.size());
+      return builder.toString();
+    }
   }
 }
diff --git hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TopologyTool.java hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TopologyTool.java
new file mode 100644
index 0000000..72358d0
--- /dev/null
+++ hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/TopologyTool.java
@@ -0,0 +1,234 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.net;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.conf.Configured;
+import org.apache.hadoop.fs.CommonConfigurationKeys;
+import org.apache.hadoop.util.Tool;
+import org.apache.hadoop.util.ToolRunner;
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileReader;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import static org.apache.hadoop.fs.CommonConfigurationKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY;
+
+public class TopologyTool extends Configured implements Tool {
+
+  private static final Log LOG = LogFactory.getLog(TopologyTool.class);
+
+  public TopologyTool() {
+  }
+
+  public TopologyTool(Configuration conf) {
+    super(conf);
+  }
+
+  private void println(CharSequence text) {
+    System.out.println(text);
+  }
+
+  private void usage() {
+    println("usage: hadoop topo test [hostname] [hostname] ...");
+    println("usage: hadoop topo testfile filename");
+  }
+
+  @Override
+  public int run(String[] args) throws Exception {
+
+    if (args.length < 1) {
+      usage();
+      return -1;
+    }
+
+    String operation = args[0];
+
+    Configuration conf = getConf();
+    String mapclass = conf.get(NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY);
+    println(NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY + "=" + mapclass);
+    AbstractDNSToSwitchMapping mapping = null;
+    try {
+      mapping = AbstractDNSToSwitchMapping.
+          createCachingDNSToSwitchMapping(conf);
+    } catch (Exception e) {
+      //classloader failures. Bail out and provide a hint of the cause
+      LOG.error("Failed to load the DNS mapping " + mapclass
+            +  ": " + e, e);
+      LOG.error("The configuration option is wrong, or the classpath is incomplete");
+      return -1;
+    }
+    println("Caching wrapper class = " + mapping.getClass());
+    String script = conf.get(
+        CommonConfigurationKeys.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY);
+    if (script != null) {
+      println("Mapping script filename= \"" + script + "\"");
+      File scriptFile = new File(script);
+      println("Mapping script path = \"" + scriptFile.getAbsolutePath() + "\"");
+      if (!scriptFile.exists() &&
+          "org.apache.hadoop.net.ScriptBasedMapping".equals(mapclass)) {
+        LOG.warn(
+            "Script file not found -the script must be in the execution path");
+      }
+    }
+    println("Instance information: " + mapping);
+    boolean singleSwitch =
+        AbstractDNSToSwitchMapping.isMappingSingleSwitch(mapping);
+    println("Topology is " + (singleSwitch ? "" : "not  ") +
+                "considered single-switch");
+
+    boolean successful;
+    if ("test".equals(operation)) {
+      successful = resolveHostnames(mapping, args, 1);
+    } else if ("testfile".equals(operation)) {
+      if (args.length != 2) {
+        usage();
+        successful = false;
+      } else {
+        String filename = args[1];
+        successful = resolveHostFile(mapping, filename);
+      }
+    } else {
+      usage();
+      successful = false;
+    }
+
+    return successful ? 0 : 1;
+  }
+
+  /**
+   * Print the topology held by the mapping
+   *
+   * @param mapping mapping to print
+   */
+  private void printTopology(AbstractDNSToSwitchMapping mapping) {
+    println("\nFinal topology:\n");
+    String topology = mapping.dumpTopology();
+    println(topology);
+  }
+
+  /**
+   * Load a file and hand its hostnames off for mapping
+   *
+   * @param mapping the mapping implementation
+   * @param filename the file to load
+   * @return true if it was considered successful
+   * @throws IOException on any IO problem
+   */
+  private boolean resolveHostFile(AbstractDNSToSwitchMapping mapping,
+                                  String filename) throws IOException {
+    BufferedReader reader = null;
+    List<String> hostnames = new ArrayList<String>();
+    try {
+      reader = new BufferedReader(new FileReader(filename));
+      String line;
+      while ((line = reader.readLine()) != null) {
+        line = line.trim();
+        if (!line.isEmpty()) {
+          hostnames.add(line);
+        }
+      }
+    } finally {
+      if (reader != null) {
+        try {
+          reader.close();
+        } catch (IOException e) {
+          LOG.warn("Error closing " + filename + " : " + e, e);
+        }
+      }
+    }
+    String hosts[] = new String[hostnames.size()];
+    hostnames.toArray(hosts);
+    return resolveHostnames(mapping, hosts, 0);
+  }
+
+  /**
+   * Test the array of hosts (or a subset thereof) for resolving in the mapper.
+   * The results are printed during the process; the final topology is then
+   * displayed.
+   *
+   * @param mapping the mapping to test
+   * @param hosts the hostnames
+   * @param offset an offset into the array: 0 means start from the beginning
+   * @return
+   */
+  private boolean resolveHostnames(AbstractDNSToSwitchMapping mapping,
+                                   String[] hosts,
+                                   int offset) {
+    int failures = 0;
+    List<String> hostnameList = new ArrayList<String>(1);
+    hostnameList.add("");
+    int l = hosts.length;
+    for (int i = offset; i < l; i++) {
+      String hostname = hosts[i];
+      hostnameList.set(0, hostname);
+      try {
+        println("Resolving " + hostname);
+        long starttime = System.nanoTime();
+        List<String> resolved = mapping.resolve(hostnameList);
+        long endtime = System.nanoTime();
+        if (resolved == null) {
+          LOG.warn("Hostname resolution returned a null list");
+          failures++;
+        } else if (resolved.size() != 1) {
+          LOG.warn("hostname resolved to a list of size " + resolved.size());
+          failures++;
+        } else {
+          StringBuilder builder = new StringBuilder();
+          builder.append("Hostname \"").append(hostname)
+              .append("\" resolved to ")
+              .append('"').append(resolved.get(0)).append("\" ");
+          double duration = (endtime - starttime) / 1e6;
+          builder.append(" in ").append(duration).append(" milliseconds");
+          println(builder);
+        }
+      } catch (Exception e) {
+        LOG.error("Error while trying to resolve host " + hostname
+                      + ": " + e,
+                  e);
+        failures++;
+      }
+    }
+    //now dump the topology
+    printTopology(mapping);
+    return failures == 0;
+  }
+
+  /**
+   * Entry point
+   *
+   * @param argv the command and its arguments
+   */
+  public static void main(String argv[]) {
+    TopologyTool topo = new TopologyTool();
+    int res;
+    try {
+      res = ToolRunner.run(topo, argv);
+    } catch (Throwable e) {
+      LOG.error("Failure: " + e, e);
+      res = 1;
+    }
+    System.exit(res);
+  }
+}
